{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1371798d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T08:21:11.948466200Z",
     "start_time": "2024-01-16T08:21:08.884877600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1741243993258192414\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 78607156\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 14952660512657211156\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3863d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6615, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# image_path = r'image\\auto_intg\\preprocess\\train_image_20240228'\n",
    "image_path=r'image\\auto_intg\\preprocess_no_cut\\train_image_20240306'\n",
    "image_files = [f for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
    "\n",
    "images = []\n",
    "for file in image_files:\n",
    "    img = cv2.imread(os.path.join(image_path, file))\n",
    "    if img is None:\n",
    "        print(f\"{file} 읽을 수 없음\")\n",
    "        continue\n",
    "\n",
    "    img = img / 255.0  # 0~1로 정규화\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d0682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6615, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_path = 'data/train_data_20240214-20240227_20240228.xlsx'\n",
    "df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "\n",
    "illum_columns = [f'illum_{i}' for i in range(1, 10)]\n",
    "\n",
    "# Extract output (illum) columns\n",
    "target_data = (df[illum_columns]).to_numpy()\n",
    "target_data[target_data < 0] = 0\n",
    "print(target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cab806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5292, 224, 224, 3)\n",
      "Testing data shape: (1323, 224, 224, 3)\n",
      "Training target shape: (5292, 9)\n",
      "Testing target shape: (1323, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Training target shape:\", y_train.shape)\n",
    "print(\"Testing target shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bd241f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       4719104   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 56, 56, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 128)     295040    \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 64)      73792     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3211264)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 28901385  \n",
      "=================================================================\n",
      "Total params: 57,146,825\n",
      "Trainable params: 57,146,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5292 samples, validate on 1323 samples\n",
      "Epoch 1/500\n",
      "5292/5292 [==============================] - 2537s - loss: 613.3734 - acc: 0.7281 - val_loss: 579.4022 - val_acc: 0.7332\n",
      "Epoch 2/500\n",
      "5292/5292 [==============================] - 2475s - loss: 611.7684 - acc: 0.7307 - val_loss: 582.2298 - val_acc: 0.7332\n",
      "Epoch 3/500\n",
      "5292/5292 [==============================] - 2593s - loss: 611.1521 - acc: 0.7307 - val_loss: 580.1708 - val_acc: 0.7332\n",
      "Epoch 4/500\n",
      "5292/5292 [==============================] - 2462s - loss: 610.6409 - acc: 0.7307 - val_loss: 579.6487 - val_acc: 0.7332\n",
      "Epoch 5/500\n",
      "5292/5292 [==============================] - 2467s - loss: 611.1146 - acc: 0.7307 - val_loss: 579.2410 - val_acc: 0.7332\n",
      "Epoch 6/500\n",
      "5292/5292 [==============================] - 2450s - loss: 610.4331 - acc: 0.7307 - val_loss: 579.4567 - val_acc: 0.7332\n",
      "Epoch 7/500\n",
      "5292/5292 [==============================] - 2458s - loss: 610.9868 - acc: 0.7307 - val_loss: 581.1469 - val_acc: 0.7332\n",
      "Epoch 8/500\n",
      "5292/5292 [==============================] - 2460s - loss: 611.2728 - acc: 0.7307 - val_loss: 580.5021 - val_acc: 0.7332\n",
      "Epoch 9/500\n",
      "5292/5292 [==============================] - 2458s - loss: 610.8096 - acc: 0.7307 - val_loss: 579.2693 - val_acc: 0.7332\n",
      "Epoch 10/500\n",
      "5292/5292 [==============================] - 2461s - loss: 611.0559 - acc: 0.7307 - val_loss: 582.6974 - val_acc: 0.7332\n",
      "Epoch 11/500\n",
      "5292/5292 [==============================] - 2457s - loss: 611.0276 - acc: 0.7307 - val_loss: 579.4998 - val_acc: 0.7332\n",
      "Epoch 12/500\n",
      "5292/5292 [==============================] - 2473s - loss: 610.9311 - acc: 0.7307 - val_loss: 580.4054 - val_acc: 0.7332\n",
      "Epoch 13/500\n",
      "5292/5292 [==============================] - 2494s - loss: 611.0348 - acc: 0.7307 - val_loss: 579.6120 - val_acc: 0.7332\n",
      "Epoch 14/500\n",
      "5292/5292 [==============================] - 2453s - loss: 610.7582 - acc: 0.7307 - val_loss: 579.5121 - val_acc: 0.7332\n",
      "Epoch 15/500\n",
      "5292/5292 [==============================] - 2456s - loss: 611.0521 - acc: 0.7307 - val_loss: 579.2660 - val_acc: 0.7332\n",
      "Epoch 16/500\n",
      "5292/5292 [==============================] - 2456s - loss: 611.1879 - acc: 0.7307 - val_loss: 579.2818 - val_acc: 0.7332\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,128,224,224]\n\t [[Node: conv2d_17/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](up_sampling2d_4/ResizeNearestNeighbor, conv2d_16/kernel/read)]]\n\t [[Node: loss/mul/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_264_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv2d_17/Conv2D', defined at:\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e4f0de359dfb>\", line 40, in <module>\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py\", line 501, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\topology.py\", line 252, in __call__\n    output = super(Layer, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 167, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,224,224]\n\t [[Node: conv2d_17/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](up_sampling2d_4/ResizeNearestNeighbor, conv2d_16/kernel/read)]]\n\t [[Node: loss/mul/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_264_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,224,224]\n\t [[Node: conv2d_17/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](up_sampling2d_4/ResizeNearestNeighbor, conv2d_16/kernel/read)]]\n\t [[Node: loss/mul/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_264_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e4f0de359dfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# Evaluate the model on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m     return self._test_loop(\n\u001b[1;32m-> 1684\u001b[1;33m         f, ins, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m         **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2478\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,224,224]\n\t [[Node: conv2d_17/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](up_sampling2d_4/ResizeNearestNeighbor, conv2d_16/kernel/read)]]\n\t [[Node: loss/mul/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_264_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv2d_17/Conv2D', defined at:\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e4f0de359dfb>\", line 40, in <module>\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py\", line 501, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\topology.py\", line 252, in __call__\n    output = super(Layer, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 167, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\witlab\\anaconda3\\envs\\gpu_test_python3.6\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,224,224]\n\t [[Node: conv2d_17/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](up_sampling2d_4/ResizeNearestNeighbor, conv2d_16/kernel/read)]]\n\t [[Node: loss/mul/_297 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_264_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Bottleneck\n",
    "model.add(Conv2D(1024, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(1024, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Decoder\n",
    "model.add(UpSampling2D())\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(UpSampling2D())\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(UpSampling2D())\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(UpSampling2D())\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "early_stopping_cb = EarlyStopping(patience =10, monitor = 'val_loss')\n",
    "checkpoint_cb = ModelCheckpoint(\"model/unet_best_model_img_no_cut_20240306.h5\", monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=2, validation_data=(X_test, y_test), callbacks=[early_stopping_cb,checkpoint_cb])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bebecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e2771",
   "metadata": {},
   "source": [
    "### 2024.02.21 데이터로 성능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r'image\\auto_intg\\preprocess_no_cut\\20240221'\n",
    "test_image_files = [f for f in os.listdir(test_image_path) if f.endswith('.jpg')]\n",
    "\n",
    "test_images = []\n",
    "for file in test_image_files:\n",
    "    img = cv2.imread(os.path.join(test_image_path, file))\n",
    "    if img is None:\n",
    "        print(f\"{file} 읽을 수 없음\")\n",
    "        continue\n",
    "\n",
    "    img = img / 255.0  # 0~1로 정규화\n",
    "    test_images.append(img)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26495504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024.02.21 조도 데이터 불러오기\n",
    "\n",
    "test_excel_path = 'data/test_data_20240221.xlsx'\n",
    "test_df = pd.read_excel(test_excel_path, engine='openpyxl')\n",
    "\n",
    "illum_columns = [f'illum_{i}' for i in range(1, 10)]\n",
    "\n",
    "# Extract output (illum) columns\n",
    "test_target_data = (test_df[illum_columns]).to_numpy()\n",
    "test_target_data[test_target_data < 0] = 0\n",
    "print(test_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_target_data.shape)\n",
    "print(pred.shape)\n",
    "print(type(test_target_data))\n",
    "print(type(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a85a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from the arrays\n",
    "actual_df = pd.DataFrame(test_target_data, columns=[f'Actual_Illum_{i+1}' for i in range(9)])\n",
    "predicted_df = pd.DataFrame(pred, columns=[f'Predicted_Illum_{i+1}' for i in range(9)])\n",
    "\n",
    "# Concatenate the DataFrames horizontally\n",
    "comparison_data = pd.concat([actual_df, predicted_df], axis=1)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_output_path = 'unet_results_20240221_test_20240318_img_no_cut.xlsx'\n",
    "comparison_data.to_excel(excel_output_path, index=False)\n",
    "\n",
    "print(f\"Comparison results saved to {excel_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "r_squared = r2_score(test_target_data, pred)\n",
    "mae = mean_absolute_error(test_target_data, pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R²):\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee1870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
